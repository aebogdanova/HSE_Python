{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДЗ №6. ИССЛЕДОВАНИЯ ТЕКСТА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. СОХРАНЕНИЕ ТЕКСТА ИЗ ФАЙЛА В ПЕРЕМЕННУЮ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from gensim.utils import tokenize\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re, os, json\n",
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(\"city_smells.txt\", \"r\", encoding = \"utf-8\")\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ПРЕДОБРАБОТКА ТЕКСТА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Ссылка на источник не является семантически значимой, поэтому убираем ее из текста\n",
    "text = re.split(\"Источники:\", text)[0]\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Разбиваем текст на предложения (в предложении сохраняются числа и пунктуация)\n",
    "sentences = sent_tokenize(text, \"russian\")\n",
    "#print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Приводим текст к нижнему регистру, избавляемся от чисел\n",
    "text_normalized = re.sub(r\"\\d+\", \"\", text.lower())\n",
    "#print(text_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Делим текст на слова, избавляемся от пунктуации, образовавшихся пустых элементов списка\n",
    "string.punctuation += '«»—…“”'\n",
    "words_list = [word.strip(string.punctuation) for word in text_normalized.split()]\n",
    "words_list = [x for x in words_list if x]\n",
    "#print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Лемматизируем слова, преобразовав список слов в строку, убираем пробелы и знак табуляции\n",
    "words_str = ' '.join(words_list)\n",
    "words_lemmatized = mystem.lemmatize(words_str)\n",
    "for x in words_lemmatized:\n",
    "    if words_lemmatized.count(\" \") > 0:\n",
    "        words_lemmatized.remove(\" \")\n",
    "words_lemmatized.remove('\\n')\n",
    "#Так как после лемматизации в список попадают знаки \"/\" и \"-\" (из \"выброс/выхлоп\" и \"слово-метка\"), убираем их\n",
    "words_lemmatized = ' '.join(words_lemmatized)\n",
    "words_lemmatized = re.sub(\" / | - \", \"\", words_lemmatized)\n",
    "words_lemmatized = words_lemmatized.split()\n",
    "#print(words_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Составляем список уникальных слов в тексте\n",
    "unique_words = set(words_lemmatized)\n",
    "#print(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. ИССЛЕДОВАНИЯ ТЕКСТА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. ОПРЕДЕЛЕНИЕ СРЕДНЕЙ ДЛИНЫ СЛОВА В ТЕКСТЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Количетво всех букв в словах (длину строки words_list) делим на количество слов (кол-во элементов списка words_list)\n",
    "letters_total = ''.join(words_list)\n",
    "a = \"Средняя длина слова в тексте: \", round((len(letters_total)/len(words_list)), 2)\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. ОПРЕДЕЛЕНИЕ СРЕДНЕЙ ДЛИНЫ ПРЕДЛОЖЕНИЯ В ТЕКСТЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Количетво всех символов в тексте (длину строки text) делим на количество предложений (кол-во элементов списка sentences)\n",
    "b = \"Средняя длина предложения в тексте: \", round(len(text)/len(sentences), 3)\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. СРАВНЕНИЕ САМОГО ДЛИННОГО ПРЕДЛОЖЕНИЯ И САМОГО КОРОТКОГО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Составляем список длин предложений (в символах)\n",
    "sentences_len = []\n",
    "[sentences_len.append(len(x)) for x in sentences]\n",
    "#Делим максимальное значение списка на минимальное\n",
    "c = \"Самое длинное предложение длиннее самого короткого в\", round(max(sentences_len)/min(sentences_len), 2) , \"раз\"\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. ОПРЕДЕЛЕНИЕ СРЕДНЕГО КОЛИЧЕСТВА ПУНКТУАЦИОННЫХ ЗНАКОВ В ПРЕДЛОЖЕНИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Составляем список всех пунктуационных знаков\n",
    "punctuation_total = re.findall(\"[\\.,;:—()\"\"«»“”…!?/]\", text)\n",
    "#Делим количество пунктуационных знаков на количество предложений\n",
    "d = \"Среднее количество пунктуационных знаков в предложении: \", round(len(punctuation_total)/len(sentences), 2)\n",
    "#print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5. ДОЛЯ УНИКАЛЬНЫХ СЛОВ ОТ ОБЩЕГО КОЛИЧЕСТВА СЛОВ В ТЕКСТЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делим количество элементов списка unique_words на количество элементов списка words_lemmatized\n",
    "e = \"Общее количество уникальных слов в тексте: \", len(unique_words)\n",
    "f = \"Доля уникальных слов в тексте (от общего количества слов) составляет:\", round(len(unique_words)/len(words_list), 2)\n",
    "#print(e,\"\\n\",f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6. ДОЛЯ СЛОВ НА ЛАТИНИЦЕ ОТ ОБЩЕГО КОЛИЧЕСТВА СЛОВ В ТЕКСТЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Составляем список слов на латинице\n",
    "latin_words = [re.findall(r\"[a-zA-Z]+\", word) for word in words_list]\n",
    "latin_words = [x for x in latin_words if x]\n",
    "#Делим количество слов на латинице на общее количество слов\n",
    "g = \"Доля слов на латинице в тексте (от общего количества слов) составляет: \", round(len(latin_words)/len(words_list), 2)\n",
    "#print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. СОХРАНЕНИЕ РЕЗУЛЬТАТОВ В ФАЙЛ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"text_analysis.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file.write(str(a)+\"\\n\"+str(b)+\"\\n\"+str(c)+\"\\n\"+str(d)+\"\\n\"+str(e)+\"\\n\"+str(f)+\"\\n\"+str(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('Средняя длина слова в тексте: ', 6.0)\\n('Средняя длина предложения в тексте: ', 141.7)\\n('Самое длинное предложение длиннее самого короткого в', 12.43, 'раз')\\n('Среднее количество пунктуационных знаков в предложении: ', 4.13)\\n('Общее количество уникальных слов в тексте: ', 311)\\n('Доля уникальных слов в тексте (от общего количества слов) составляет:', 0.53)\\n('Доля слов на латинице в тексте (от общего количества слов) составляет: ', 0.02)\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file = open(\"text_analysis.txt\",'r')\n",
    "my_file = my_file.read()\n",
    "my_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
